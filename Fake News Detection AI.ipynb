{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import heapq\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import nltk\n",
    "\n",
    "# import lemmetizer modules\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# get set of stopwords\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing train dataset into a dataframe\n",
    "\n",
    "trainDataset = pd.read_csv(\"Dataset/train.csv\")[\"text\"]\n",
    "trainDataset.dropna(inplace = True)\n",
    "trainDataset.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing test dataset into a dataframe\n",
    "\n",
    "testDataset = pd.read_csv(\"Dataset/test.csv\")[\"text\"]\n",
    "testDataset.dropna(inplace = True)\n",
    "testDataset.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BOW:\n",
    "    # function to extract unnecessary word from sentence\n",
    "    def extractWord(self, word):\n",
    "        ignore = set(stopwords.words('english'))\n",
    "        words = re.sub(\"[^\\w]\", \" \", word).split()\n",
    "        words = ''.join(words).lower()\n",
    "        \n",
    "        if words in ignore:\n",
    "            return ''\n",
    "        \n",
    "        return words\n",
    "    \n",
    "    # function to tokenize all the sentences in the dataset\n",
    "    def tokenize(self, sentence):\n",
    "        words = []\n",
    "\n",
    "        sentence = sentence.split()\n",
    "        for word in sentence:\n",
    "            w = lemmatizer.lemmatize(self.extractWord(word))\n",
    "\n",
    "            if w != '':\n",
    "                words.append(w)\n",
    "\n",
    "        return words\n",
    "    \n",
    "    # create bag of words\n",
    "    def createBOW(self, dataframe):\n",
    "        bow = [{} for _ in range(len(dataframe))]\n",
    "\n",
    "        for i, sentence in enumerate(dataframe):\n",
    "            words = sorted(self.tokenize(sentence))\n",
    "            \n",
    "            for word in words:\n",
    "                if word not in bow[i].keys():\n",
    "                    bow[i][word] = 1\n",
    "                else:\n",
    "                    bow[i][word] += 1\n",
    "                    \n",
    "            clear_output(wait=True)\n",
    "            print(f'Creating Bag Of Words: {i + 1}/{len(bow)}')\n",
    "                    \n",
    "        return bow\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.data = self.createBOW(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainBOW = BOW(trainDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testBOW = BOW(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.DataFrame(trainBOW.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF = pd.DataFrame(testBOW.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.to_csv('Dataset/BOW/train_bow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF.to_csv('Dataset/BOW/test_bow.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Bag Of Words: 5/5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2012</th>\n",
       "      <th>2016</th>\n",
       "      <th>28</th>\n",
       "      <th>30</th>\n",
       "      <th>30something</th>\n",
       "      <th>78</th>\n",
       "      <th>ablaze</th>\n",
       "      <th>abusive</th>\n",
       "      <th>according</th>\n",
       "      <th>acting</th>\n",
       "      <th>...</th>\n",
       "      <th>six</th>\n",
       "      <th>stated</th>\n",
       "      <th>stoned</th>\n",
       "      <th>stoning</th>\n",
       "      <th>unit</th>\n",
       "      <th>warrant</th>\n",
       "      <th>watched</th>\n",
       "      <th>wife</th>\n",
       "      <th>without</th>\n",
       "      <th>written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1103 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   2012  2016   28   30  30something   78  ablaze  abusive  according  acting  \\\n",
       "0   1.0   2.0  1.0  1.0          1.0  1.0     1.0      1.0        3.0     1.0   \n",
       "1   NaN   2.0  NaN  NaN          NaN  NaN     NaN      NaN        NaN     NaN   \n",
       "2   NaN   1.0  NaN  NaN          NaN  NaN     NaN      NaN        NaN     NaN   \n",
       "3   NaN   NaN  1.0  NaN          NaN  NaN     NaN      NaN        NaN     NaN   \n",
       "4   NaN   NaN  NaN  NaN          NaN  NaN     NaN      NaN        1.0     NaN   \n",
       "\n",
       "   ...  six  stated  stoned  stoning  unit  warrant  watched  wife  without  \\\n",
       "0  ...  NaN     NaN     NaN      NaN   NaN      NaN      NaN   NaN      NaN   \n",
       "1  ...  NaN     NaN     NaN      NaN   NaN      NaN      NaN   NaN      NaN   \n",
       "2  ...  NaN     NaN     NaN      NaN   NaN      NaN      NaN   NaN      NaN   \n",
       "3  ...  NaN     NaN     NaN      NaN   NaN      NaN      NaN   NaN      NaN   \n",
       "4  ...  1.0     2.0     1.0      2.0   1.0      1.0      1.0   1.0      1.0   \n",
       "\n",
       "   written  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      2.0  \n",
       "\n",
       "[5 rows x 1103 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = BOW(trainDataset.head())\n",
    "pd.DataFrame(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
